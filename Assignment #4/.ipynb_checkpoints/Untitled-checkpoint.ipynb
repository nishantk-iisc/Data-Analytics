{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3b5f468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utility.py\n"
     ]
    }
   ],
   "source": [
    "%%file utility.py\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def get_entorpy(f_rate0, f_rate1):\n",
    "    par_m = 24\n",
    "    par_lambda = 250\n",
    "    bias = 1/(2*par_m*par_lambda)\n",
    "    entropy_relative = []\n",
    "    assert len(f_rate0) == len(f_rate1)\n",
    "    count_valid_f_rate = 0\n",
    "    for i in range(len(f_rate0)):\n",
    "        if np.isnan(f_rate0[i]) or np.isnan(f_rate1[i]):\n",
    "            pass\n",
    "        else:\n",
    "            if f_rate0[i] > bias:\n",
    "                entropy_relative_neu_i = f_rate0[i]*math.log((f_rate0[i] - bias)/(f_rate1[i] + bias)) - f_rate0[i] + f_rate1[i]\n",
    "                entropy_relative.append(entropy_relative_neu_i)\n",
    "            else:\n",
    "                entropy_relative.append(f_rate1[i])\n",
    "            count_valid_f_rate += 1\n",
    "    return np.sum(entropy_relative)/count_valid_f_rate\n",
    "\n",
    "\n",
    "def get_dist_l1(f_rate0, f_rate1):\n",
    "    dist_l1 = []\n",
    "    assert len(f_rate0) == len(f_rate1)\n",
    "    count_valid_f_rate = 0\n",
    "    for i in range(len(f_rate0)):\n",
    "        if np.isnan(f_rate0[i]) or np.isnan(f_rate1[i]):\n",
    "            pass\n",
    "        else:\n",
    "            dist_l1_neuron_i = abs(f_rate0[i] - f_rate1[i])\n",
    "            dist_l1.append(dist_l1_neuron_i)\n",
    "        count_valid_f_rate += 1\n",
    "\n",
    "    return np.sum(dist_l1)/len(f_rate1)\n",
    "\n",
    "\n",
    "def get_avg_search_times(react_times, base_line):\n",
    "    return np.nanmean(react_times) - base_line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "938ede8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gamma_fit.py\n"
     ]
    }
   ],
   "source": [
    "%%file gamma_fit.py\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from random import shuffle\n",
    "import itertools\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "class Gamma_Dist_Fitter:\n",
    "\n",
    "    def __init__(self, look_up_time_data):\n",
    "        self._look_up_time_data = look_up_time_data\n",
    "        self._grps_count = look_up_time_data.shape[1]\n",
    "        self._rand_grps = None\n",
    "        self._nors_mean_list = []\n",
    "        self._nor_stddev_list = []\n",
    "        self._shape_val = None\n",
    "        self._rate_val = None\n",
    "\n",
    "    def select_grps_randomly(self):\n",
    "        random_list = []\n",
    "        while len(random_list) < self._grps_count//2:\n",
    "            random_number = random.randint(0, self._grps_count-1)\n",
    "            if random_number not in random_list:\n",
    "                random_list.append(random_number)\n",
    "        print('Random Numbers group :: ', random_list)\n",
    "        self._rand_grps = random_list\n",
    "\n",
    "    def mean_sd_rand_grps(self):\n",
    "        for idx in self._rand_grps:\n",
    "            srch_time_coli = np.array(self._look_up_time_data.values[:, idx][2:]).astype(np.float64)\n",
    "            mean_ = np.nanmean(srch_time_coli)\n",
    "            stddev_ = math.sqrt(np.nanvar(srch_time_coli))\n",
    "            self._nors_mean_list.append(mean_)\n",
    "            self._nor_stddev_list.append(stddev_)\n",
    "        print('Means :: ', self._nors_mean_list)\n",
    "        print('Standard Deviations :: ', self._nor_stddev_list)\n",
    "\n",
    "    def mean_vs_sd_plot(self):\n",
    "        ax = plt.subplot(111)\n",
    "        plt.xlabel('Mean')\n",
    "        plt.ylabel('Standard Deviation (sd)')\n",
    "        ax.scatter(self._nors_mean_list, self._nor_stddev_list, color='r')\n",
    "        plt.savefig('./output_plots/gamma_sd_mean.png')\n",
    "        print(\"Plot Gamma std dev is saved.\\n\")\n",
    "        plt.close()\n",
    "\n",
    "    def find_shape_para_values(self):\n",
    "        para_line = np.polyfit(self._nors_mean_list, self._nor_stddev_list, deg=1, full=True)\n",
    "        self._shape_val = 1/math.pow(para_line[0][0], 2)\n",
    "        print('Shape parameter :: ', self._shape_val)\n",
    "\n",
    "    def find_rate_para_and_kolmogorov_stat(self):\n",
    "        groups_left_outs = []\n",
    "        nors_mean_list = []\n",
    "        var_value_list = []\n",
    "        cdf_values = []\n",
    "        for idx in range(self._grps_count):\n",
    "            if idx not in self._rand_grps:\n",
    "                groups_left_outs.append(idx)\n",
    "\n",
    "        for idx in groups_left_outs:\n",
    "            srch_time_coli = np.array(self._look_up_time_data.values[:, idx][2:]).astype(np.float64)\n",
    "            clean_srch_time_coli = [time for time in srch_time_coli if str(time) != 'nan']\n",
    "            shuffle(clean_srch_time_coli)\n",
    "            rdmized_search_times = clean_srch_time_coli[0:len(clean_srch_time_coli)//2]\n",
    "            cdf_values.append(clean_srch_time_coli[len(clean_srch_time_coli)//2:len(clean_srch_time_coli)])\n",
    "            mean_ = np.nanmean(rdmized_search_times)\n",
    "            variance_ = np.nanvar(rdmized_search_times)\n",
    "            nors_mean_list.append(mean_)\n",
    "            var_value_list.append(variance_)\n",
    "\n",
    "\n",
    "        para_line = np.polyfit(nors_mean_list, var_value_list, deg=1, full=True)\n",
    "        self._rate_val = 1/para_line[0][0]\n",
    "        print('Rate parameter :: ', self._rate_val)\n",
    "\n",
    "        cdf_values = list(itertools.chain.from_iterable(cdf_values))\n",
    "        sorted_cdf_value = np.sort(cdf_values)\n",
    "        \n",
    "        # Plot empirical gamma distribution\n",
    "        y_cdf_emp_value = np.arange(len(sorted_cdf_value)) / float(len(sorted_cdf_value) - 1)\n",
    "        plt.plot(sorted_cdf_value, y_cdf_emp_value)\n",
    "\n",
    "        # # Plot gamma distribution\n",
    "        x_gamma_val = np.linspace(0, sorted_cdf_value[-1], 200)\n",
    "        y_gamma_val = stats.gamma.cdf(x_gamma_val, a=self._shape_val, scale=1/self._rate_val)\n",
    "        plt.plot(x_gamma_val, y_gamma_val, color='r')\n",
    "        plt.savefig('./output_plots/gamma_dist.png')\n",
    "        plt.close()\n",
    "\n",
    "        y_pdf = stats.gamma.rvs(size=len(cdf_values), a=self._shape_val, scale=1 / self._rate_val)\n",
    "        kst_test = stats.ks_2samp(sorted_cdf_value, y_pdf)\n",
    "        print('Kolmogorov statistic :: ', kst_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df4b9769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting line_fit.py\n"
     ]
    }
   ],
   "source": [
    "%%file line_fit.py\n",
    "\n",
    "import numpy as np\n",
    "import utility\n",
    "from scipy.stats.mstats import gmean\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class LineFit:\n",
    "\n",
    "    def __init__(self, srch_time_data, fire_rate_data):\n",
    "        self._srch_time_data = srch_time_data\n",
    "        self._fire_rate_data = fire_rate_data\n",
    "        self._avg_search_times = []\n",
    "        self._relative_entropy_data = []\n",
    "        self._l1_dist_data = []\n",
    "        self._inverse_search_times = []\n",
    "        self._ratio_am_gm_search_entropy = None\n",
    "        self._ratio_am_gm_search_l1_distance = None\n",
    "\n",
    "    def find_avg_search_time(self):\n",
    "        len_search_data = self._srch_time_data.shape[1]\n",
    "        print('Size of search data list :: ' + str(len_search_data))\n",
    "        for i in range(len_search_data):\n",
    "            search_time_col_i = np.array(self._srch_time_data.values[:, i][2:]).astype(np.float64)\n",
    "            # print(search_time_col_i[2:])\n",
    "            avg_search_time = utility.get_avg_search_times(search_time_col_i, 328)\n",
    "            self._avg_search_times.append(avg_search_time)\n",
    "            self._inverse_search_times = [1000 / search_time for search_time in self._avg_search_times]\n",
    "        return self._avg_search_times\n",
    "\n",
    "    def calc_entropy_and_l1_dist(self):\n",
    "        set_count = 4\n",
    "        column_count_per_set = 6\n",
    "        for i in range(set_count):\n",
    "            if i != 3:\n",
    "                for j in range(column_count_per_set // 2):\n",
    "                    column_index = i * column_count_per_set + 2 * j\n",
    "                    # print(column_index)\n",
    "                    f_rate_0 = np.array(self._fire_rate_data.values[:, column_index][2:]).astype(np.float64)\n",
    "                    f_rate_1 = np.array(self._fire_rate_data.values[:, column_index + 1][2:]).astype(np.float64)\n",
    "                    relative_entropy_ij = utility.get_entorpy(f_rate_0, f_rate_1)\n",
    "                    self._relative_entropy_data.append(relative_entropy_ij)\n",
    "                    l1_distance_ij = utility.get_dist_l1(f_rate_0, f_rate_1)\n",
    "                    self._l1_dist_data.append(l1_distance_ij)\n",
    "\n",
    "                    relative_entropy_ji = utility.get_entorpy(f_rate_1, f_rate_0)\n",
    "                    self._relative_entropy_data.append(relative_entropy_ji)\n",
    "                    l1_distance_ji = utility.get_dist_l1(f_rate_1, f_rate_0)\n",
    "                    self._l1_dist_data.append(l1_distance_ji)\n",
    "            else:\n",
    "                for j in range(3):\n",
    "                    column_index = i * column_count_per_set + 2 * j\n",
    "                    f_rate_0 = np.array(self._fire_rate_data.values[:, column_index][2:]).astype(np.float64)\n",
    "                    f_rate_1 = np.array(self._fire_rate_data.values[:, column_index + 2][2:]).astype(np.float64)\n",
    "                    relative_entropy_ij_1 = utility.get_entorpy(f_rate_0, f_rate_1)\n",
    "                    l1_distance_ij_1 = utility.get_dist_l1(f_rate_0, f_rate_1)\n",
    "                    relative_entropy_ji_1 = utility.get_entorpy(f_rate_1, f_rate_0)\n",
    "                    l1_distance_ji_1 = utility.get_dist_l1(f_rate_1, f_rate_0)\n",
    "\n",
    "                    f_rate_0 = np.array(self._fire_rate_data.values[:, column_index][2:]).astype(np.float64)\n",
    "                    f_rate_1 = np.array(self._fire_rate_data.values[:, column_index + 3][2:]).astype(np.float64)\n",
    "                    relative_entropy_ij_2 = utility.get_entorpy(f_rate_0, f_rate_1)\n",
    "                    l1_distance_ij_2 = utility.get_dist_l1(f_rate_0, f_rate_1)\n",
    "                    relative_entropy_ji_2 = utility.get_entorpy(f_rate_1, f_rate_0)\n",
    "                    l1_distance_ji_2 = utility.get_dist_l1(f_rate_1, f_rate_0)\n",
    "\n",
    "                    f_rate_0 = np.array(self._fire_rate_data.values[:, column_index + 1][2:]).astype(np.float64)\n",
    "                    f_rate_1 = np.array(self._fire_rate_data.values[:, column_index + 2][2:]).astype(np.float64)\n",
    "                    relative_entropy_ij_3 = utility.get_entorpy(f_rate_0, f_rate_1)\n",
    "                    l1_distance_ij_3 = utility.get_dist_l1(f_rate_0, f_rate_1)\n",
    "                    relative_entropy_ji_3 = utility.get_entorpy(f_rate_1, f_rate_0)\n",
    "                    l1_distance_ji_3 = utility.get_dist_l1(f_rate_1, f_rate_0)\n",
    "\n",
    "                    f_rate_0 = np.array(self._fire_rate_data.values[:, column_index + 1][2:]).astype(np.float64)\n",
    "                    f_rate_1 = np.array(self._fire_rate_data.values[:, column_index + 3][2:]).astype(np.float64)\n",
    "                    relative_entropy_ij_4 = utility.get_entorpy(f_rate_0, f_rate_1)\n",
    "                    l1_distance_ij_4 = utility.get_dist_l1(f_rate_0, f_rate_1)\n",
    "                    relative_entropy_ji_4 = utility.get_entorpy(f_rate_1, f_rate_0)\n",
    "                    l1_distance_ji_4 = utility.get_dist_l1(f_rate_1, f_rate_0)\n",
    "\n",
    "                    relative_entropy_ij = np.mean([relative_entropy_ij_1, relative_entropy_ij_2, relative_entropy_ij_3,\n",
    "                                                   relative_entropy_ij_4])\n",
    "                    l1_distance_ij = np.mean([l1_distance_ij_1, l1_distance_ij_2, l1_distance_ij_3, l1_distance_ij_4])\n",
    "                    self._relative_entropy_data.append(relative_entropy_ij)\n",
    "                    self._l1_dist_data.append(l1_distance_ij)\n",
    "\n",
    "                    relative_entropy_ji = np.mean([relative_entropy_ji_1, relative_entropy_ji_2, relative_entropy_ji_3,\n",
    "                                                   relative_entropy_ji_4])\n",
    "                    l1_distance_ji = np.mean([l1_distance_ji_1, l1_distance_ji_2, l1_distance_ji_3, l1_distance_ji_4])\n",
    "                    self._relative_entropy_data.append(relative_entropy_ji)\n",
    "                    self._l1_dist_data.append(l1_distance_ji)\n",
    "\n",
    "        print('Size of relative entropy list :: ' + str(len(self._relative_entropy_data)))\n",
    "        # print(self._relative_entropy_data)\n",
    "        print('Size of L1 distance list :: ' + str(len(self._l1_dist_data)))\n",
    "        # print(self._l1_dist_data)\n",
    "        return self._relative_entropy_data, self._l1_dist_data\n",
    "\n",
    "    @staticmethod\n",
    "    def _fit_straight_line_through_origin(x, y):\n",
    "        x = x[:,np.newaxis]\n",
    "        a, residuals, _, _ = np.linalg.lstsq(x, y, rcond=None)\n",
    "        # print(a)\n",
    "        # print(residuals)\n",
    "        return a, residuals\n",
    "\n",
    "    def plot_srch_vs_entropy(self):\n",
    "        ax = plt.subplot(111)\n",
    "        plt.xlabel('Relative Entropy distance')\n",
    "        plt.gca().set_ylabel(r'$s^{-1}$')\n",
    "        ax.scatter(self._relative_entropy_data, self._inverse_search_times, c='red')\n",
    "        slope, residual_error = LineFit._fit_straight_line_through_origin(np.array(self._relative_entropy_data),\n",
    "                                                             np.array(self._inverse_search_times))\n",
    "        print('Slope for relative entropy vs. inverse search time curve :: ', slope[0])\n",
    "        print('Residual error for the straight line fit for relative entropy :: ', residual_error[0])\n",
    "        ax.plot(self._relative_entropy_data, slope*self._relative_entropy_data)\n",
    "        plt.savefig('./output_plots/relative_entropy.png')\n",
    "        plt.close()\n",
    "        # plt.show()\n",
    "\n",
    "    def plot_srch_vs_l1_dist(self):\n",
    "        ax = plt.subplot(111)\n",
    "        plt.xlabel('L1 distance')\n",
    "        plt.gca().set_ylabel(r'$s^{-1}$')\n",
    "        ax.scatter(self._l1_dist_data, self._inverse_search_times, c='red')\n",
    "        slope, residual_error = LineFit._fit_straight_line_through_origin(np.array(self._l1_dist_data),\n",
    "                                                             np.array(self._inverse_search_times))\n",
    "        print('Slope for l1 distance vs. inverse search time curve :: ', slope[0])\n",
    "        print('Residual error for the straight line fit for l1 distance :: ', residual_error[0])\n",
    "        ax.plot(self._l1_dist_data, slope * self._l1_dist_data)\n",
    "        plt.savefig('./output_plots/l1_distance.png')\n",
    "        plt.close()\n",
    "        # plt.show()\n",
    "\n",
    "    def calc_am_gm_spread(self):\n",
    "        product_search_entropy = np.multiply(self._avg_search_times, self._relative_entropy_data)\n",
    "        # print(len(product_search_entropy))\n",
    "        product_search_l1_distance = np.multiply(self._avg_search_times, self._l1_dist_data)\n",
    "        # print(len(product_search_l1_distance))\n",
    "\n",
    "        AM_product_search_entropy = np.mean(product_search_entropy)\n",
    "        GM_product_search_entropy = gmean(product_search_entropy)\n",
    "        print('Arithmetic mean for search * relative entropy :: ' + str(AM_product_search_entropy))\n",
    "        print('Geometric mean for search * relative entropy :: ' + str(GM_product_search_entropy))\n",
    "\n",
    "        AM_product_search_l1_distance = np.mean(product_search_l1_distance)\n",
    "        GM_product_search_l1_distance = gmean(product_search_l1_distance)\n",
    "        print('Arithmetic mean for search * L1 distance :: ' + str(AM_product_search_l1_distance))\n",
    "        print('Geometric mean for search * L1 distance :: ' + str(GM_product_search_l1_distance))\n",
    "\n",
    "        self._ratio_am_gm_search_entropy = AM_product_search_entropy / GM_product_search_entropy\n",
    "        print('Ratio of AM and GM for search * relative entropy :: ' + str(self._ratio_am_gm_search_entropy))\n",
    "\n",
    "        self._ratio_am_gm_search_l1_distance = AM_product_search_l1_distance / GM_product_search_l1_distance\n",
    "        print('Ratio of AM and GM for search * L1 distance :: ' + str(self._ratio_am_gm_search_l1_distance))\n",
    "\n",
    "        return self._ratio_am_gm_search_entropy, self._ratio_am_gm_search_l1_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d179f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%file main.py\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import gmean\n",
    "import pandas as pd\n",
    "import line_fit as lf\n",
    "import gamma_fit as gf\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Visual Neuroscience!')\n",
    "    fire_rate_data = pd.read_csv('../data/02_data_visual_neuroscience_firingrates.csv')\n",
    "    srch_time_data = pd.read_csv('../data/02_data_visual_neuroscience_searchtimes.csv')\n",
    "\n",
    "    # First part - Fit straight line\n",
    "    line_fit_ = lf.LineFit(srch_time_data, fire_rate_data)\n",
    "    avg_search_times = line_fit_.find_avg_search_time()\n",
    "    relative_entropy_data, l1_distance_data = line_fit_.calc_entropy_and_l1_dist()\n",
    "    line_fit_.plot_srch_vs_l1_dist()\n",
    "    line_fit_.plot_srch_vs_entropy()\n",
    "    ratio_am_gm_search_entropy, ratio_am_gm_search_l1_distance = line_fit_.calc_am_gm_spread()\n",
    "\n",
    "    # Second part - Fit Gamma Distribution\n",
    "    gamma_fitter = gf.Gamma_Dist_Fitter(srch_time_data)\n",
    "    gamma_fitter.select_grps_randomly()\n",
    "    gamma_fitter.mean_sd_rand_grps()\n",
    "    gamma_fitter.mean_vs_sd_plot()\n",
    "    gamma_fitter.find_shape_para_values()\n",
    "    gamma_fitter.find_rate_para_and_kolmogorov_stat()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b76c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653cf8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
